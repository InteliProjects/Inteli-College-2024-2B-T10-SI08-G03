{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a classe de análise\n",
    "class ReqMatAnalysis:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path  \n",
    "        self.data = None  \n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Carrega o dataset a partir do caminho especificado e exibe as primeiras linhas.\"\"\"\n",
    "        self.data = pd.read_csv(self.file_path) \n",
    "        return self.data.head() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = ReqMatAnalysis('/Users/freddymesterharari/Documents/GitHub/2024-2B-T10-SI08-G03/src/aead/TABELA_BIG_DATA_REQ_MAT_202410111115.csv')\n",
    "analysis.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReqMatAnalysis:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.data = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Carrega o dataset a partir do caminho especificado e exibe as primeiras linhas.\"\"\"\n",
    "        self.data = pd.read_csv(self.file_path)\n",
    "        return self.data.head()\n",
    "    \n",
    "    def data_overview(self):\n",
    "        \"\"\"Exibe informações gerais sobre o dataset e valores ausentes por coluna.\"\"\"\n",
    "        print(\"Informações gerais do dataset:\")\n",
    "        info = self.data.info() \n",
    "        print(\"\\nValores ausentes por coluna:\")\n",
    "        missing_values = self.data.isnull().sum() \n",
    "        print(missing_values)\n",
    "        return info, missing_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = ReqMatAnalysis('TABELA_BIG_DATA_REQ_MAT_202410111115.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.data_overview()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReqMatAnalysis:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.data = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Carrega o dataset a partir do caminho especificado e exibe as primeiras linhas.\"\"\"\n",
    "        self.data = pd.read_csv(self.file_path)\n",
    "        return self.data.head()\n",
    "    \n",
    "    def data_overview(self):\n",
    "        \"\"\"Exibe informações gerais sobre o dataset e valores ausentes por coluna.\"\"\"\n",
    "        print(\"Informações gerais do dataset:\")\n",
    "        info = self.data.info()\n",
    "        print(\"\\nValores ausentes por coluna:\")\n",
    "        missing_values = self.data.isnull().sum()\n",
    "        print(missing_values)\n",
    "        return info, missing_values\n",
    "    \n",
    "    def descriptive_statistics(self):\n",
    "        \"\"\"Gera e exibe estatísticas descritivas para colunas numéricas do dataset.\"\"\"\n",
    "        print(\"Estatísticas Descritivas das Variáveis Numéricas:\")\n",
    "        stats = self.data.describe()\n",
    "        print(stats)\n",
    "        return stats\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar a classe novamente\n",
    "analysis = ReqMatAnalysis('TABELA_BIG_DATA_REQ_MAT_202410111115.csv')\n",
    "analysis.load_data()  \n",
    "analysis.descriptive_statistics() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReqMatAnalysis:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.data = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Carrega o dataset a partir do caminho especificado e exibe as primeiras linhas.\"\"\"\n",
    "        self.data = pd.read_csv(self.file_path)\n",
    "        return self.data.head()\n",
    "    \n",
    "    def data_overview(self):\n",
    "        \"\"\"Exibe informações gerais sobre o dataset e valores ausentes por coluna.\"\"\"\n",
    "        print(\"Informações gerais do dataset:\")\n",
    "        info = self.data.info()\n",
    "        print(\"\\nValores ausentes por coluna:\")\n",
    "        missing_values = self.data.isnull().sum()\n",
    "        print(missing_values)\n",
    "        return info, missing_values\n",
    "    \n",
    "    def descriptive_statistics(self):\n",
    "        \"\"\"Gera e exibe estatísticas descritivas para colunas numéricas do dataset.\"\"\"\n",
    "        print(\"Estatísticas Descritivas das Variáveis Numéricas:\")\n",
    "        stats = self.data.describe()\n",
    "        print(stats)\n",
    "        return stats\n",
    "    \n",
    "    def visualize_distributions(self):\n",
    "        \"\"\"Visualiza distribuições das variáveis numéricas usando histogramas e boxplots.\"\"\"\n",
    "        self.data.hist(bins=20, figsize=(15, 15))\n",
    "        plt.suptitle(\"Distribuição das Variáveis Numéricas\", fontsize=20)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        sns.boxplot(data=self.data.select_dtypes(include=[np.number]))\n",
    "        plt.title(\"Boxplot das Variáveis Numéricas\")\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = ReqMatAnalysis('TABELA_BIG_DATA_REQ_MAT_202410111115.csv')\n",
    "analysis.load_data()  \n",
    "analysis.visualize_distributions() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore  \n",
    "\n",
    "class ReqMatAnalysis:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.data = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Carrega o dataset a partir do caminho especificado e exibe as primeiras linhas.\"\"\"\n",
    "        self.data = pd.read_csv(self.file_path)\n",
    "        return self.data.head()\n",
    "    \n",
    "    def data_overview(self):\n",
    "        \"\"\"Exibe informações gerais sobre o dataset e valores ausentes por coluna.\"\"\"\n",
    "        print(\"Informações gerais do dataset:\")\n",
    "        info = self.data.info()\n",
    "        print(\"\\nValores ausentes por coluna:\")\n",
    "        missing_values = self.data.isnull().sum()\n",
    "        print(missing_values)\n",
    "        return info, missing_values\n",
    "    \n",
    "    def descriptive_statistics(self):\n",
    "        \"\"\"Gera e exibe estatísticas descritivas para colunas numéricas do dataset.\"\"\"\n",
    "        print(\"Estatísticas Descritivas das Variáveis Numéricas:\")\n",
    "        stats = self.data.describe()\n",
    "        print(stats)\n",
    "        return stats\n",
    "    \n",
    "    def visualize_distributions(self):\n",
    "        \"\"\"Visualiza distribuições das variáveis numéricas usando histogramas e boxplots.\"\"\"\n",
    "        self.data.hist(bins=20, figsize=(15, 15))\n",
    "        plt.suptitle(\"Distribuição das Variáveis Numéricas\", fontsize=20)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        sns.boxplot(data=self.data.select_dtypes(include=[np.number]))\n",
    "        plt.title(\"Boxplot das Variáveis Numéricas\")\n",
    "        plt.show()\n",
    "\n",
    "    def correlation_matrix(self):\n",
    "        \"\"\"Gera e exibe a matriz de correlação para variáveis numéricas com um heatmap.\"\"\"\n",
    "        numeric_data = self.data.select_dtypes(include=[np.number])\n",
    "        correlation_matrix = numeric_data.corr()\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", square=True)\n",
    "        plt.title(\"Matriz de Correlação das Variáveis Numéricas\")\n",
    "        plt.show()\n",
    "\n",
    "    def detect_outliers(self):\n",
    "        \"\"\"Detecta e exibe a quantidade de outliers em cada variável numérica usando z-scores.\"\"\"\n",
    "        z_scores = np.abs(zscore(self.data.select_dtypes(include=[np.number])))\n",
    "        \n",
    "        outliers = (z_scores > 3).sum(axis=0)\n",
    "        \n",
    "        print(\"Número de outliers em cada coluna:\")\n",
    "        print(outliers)\n",
    "        return outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificação da classe para aceitar um DataFrame diretamente (para o caso de testes sem o arquivo)\n",
    "from scipy.stats import zscore  \n",
    "class ReqMatAnalysis:\n",
    "    def __init__(self, file_path=None, data=None):\n",
    "        self.file_path = file_path\n",
    "        self.data = data  \n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Carrega o dataset a partir do caminho especificado e exibe as primeiras linhas.\"\"\"\n",
    "        if self.file_path:\n",
    "            self.data = pd.read_csv(self.file_path)\n",
    "        return self.data.head()\n",
    "    \n",
    "    def detect_outliers(self):\n",
    "        \"\"\"Detecta e exibe a quantidade de outliers em cada variável numérica usando z-scores.\"\"\"\n",
    "        z_scores = np.abs(zscore(self.data.select_dtypes(include=[np.number])))\n",
    "        outliers = (z_scores > 3).sum(axis=0)\n",
    "        \n",
    "        print(\"Número de outliers em cada coluna:\")\n",
    "        print(outliers)\n",
    "        return outliers\n",
    "\n",
    "data_example = pd.DataFrame({\n",
    "    'coluna1': [1, 2, 3, 100, 5, 6, 7, 8, 9, 10],\n",
    "    'coluna2': [10, 20, 30, 40, 50, 1000, 70, 80, 90, 100],\n",
    "    'coluna3': [5, 3, 8, 2, 8, 9, 100, 4, 5, 3]\n",
    "})\n",
    "\n",
    "analysis = ReqMatAnalysis(data=data_example)\n",
    "analysis.detect_outliers()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class ReqMatAnalysis:\n",
    "    def __init__(self, file_path=None, data=None):\n",
    "        self.file_path = file_path\n",
    "        self.data = data\n",
    "\n",
    "    def load_data(self):\n",
    "        if self.file_path:\n",
    "            self.data = pd.read_csv(self.file_path)\n",
    "        return self.data.head()\n",
    "    \n",
    "    def detect_outliers(self):\n",
    "        z_scores = np.abs(zscore(self.data.select_dtypes(include=[np.number])))\n",
    "        outliers = (z_scores > 3).sum(axis=0)\n",
    "        print(\"Número de outliers em cada coluna:\")\n",
    "        print(outliers)\n",
    "        return outliers\n",
    "    \n",
    "    def handle_missing_values(self):\n",
    "        \"\"\"Identifica e trata valores ausentes no dataset.\"\"\"\n",
    "        missing_data = self.data.isnull().sum()\n",
    "        missing_data = missing_data[missing_data > 0]\n",
    "        \n",
    "        print(\"Valores ausentes antes do tratamento:\")\n",
    "        print(missing_data)\n",
    "        \n",
    "        for column in missing_data.index:\n",
    "            if self.data[column].dtype in [np.float64, np.int64]:\n",
    "                self.data[column].fillna(self.data[column].median(), inplace=True)\n",
    "            else:\n",
    "                self.data[column].fillna(self.data[column].mode()[0], inplace=True)\n",
    "        \n",
    "        print(\"\\nValores ausentes após o tratamento:\")\n",
    "        print(self.data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma instância com o DataFrame de exemplo\n",
    "analysis = ReqMatAnalysis(data=data_example)\n",
    "analysis.handle_missing_values()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class ReqMatAnalysis:\n",
    "    def __init__(self, file_path=None, data=None):\n",
    "        self.file_path = file_path\n",
    "        self.data = data\n",
    "\n",
    "    def load_data(self):\n",
    "        if self.file_path:\n",
    "            self.data = pd.read_csv(self.file_path)\n",
    "        return self.data.head()\n",
    "    \n",
    "    def detect_outliers(self):\n",
    "        z_scores = np.abs(zscore(self.data.select_dtypes(include=[np.number])))\n",
    "        outliers = (z_scores > 3).sum(axis=0)\n",
    "        print(\"Número de outliers em cada coluna:\")\n",
    "        print(outliers)\n",
    "        return outliers\n",
    "    \n",
    "    def handle_missing_values(self):\n",
    "        missing_data = self.data.isnull().sum()\n",
    "        missing_data = missing_data[missing_data > 0]\n",
    "        \n",
    "        print(\"Valores ausentes antes do tratamento:\")\n",
    "        print(missing_data)\n",
    "        \n",
    "        for column in missing_data.index:\n",
    "            if self.data[column].dtype in [np.float64, np.int64]:\n",
    "                self.data[column].fillna(self.data[column].median(), inplace=True)\n",
    "            else:\n",
    "                self.data[column].fillna(self.data[column].mode()[0], inplace=True)\n",
    "        \n",
    "        print(\"\\nValores ausentes após o tratamento:\")\n",
    "        print(self.data.isnull().sum())\n",
    "        \n",
    "    def apply_pca(self):\n",
    "        \"\"\"Aplica PCA para reduzir as variáveis numéricas a duas dimensões e exibe o gráfico 2D.\"\"\"\n",
    "        numeric_data = self.data.select_dtypes(include=[np.number])\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        normalized_data = scaler.fit_transform(numeric_data)\n",
    "        \n",
    "        pca = PCA(n_components=2)\n",
    "        pca_result = pca.fit_transform(normalized_data)\n",
    "        \n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.5)\n",
    "        plt.xlabel(\"Componente Principal 1\")\n",
    "        plt.ylabel(\"Componente Principal 2\")\n",
    "        plt.title(\"Visualização em 2D com PCA\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma instância usando o DataFrame de exemplo ou o seu dataset\n",
    "analysis = ReqMatAnalysis(data=data_example)  \n",
    "analysis.apply_pca()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusão\n",
    "\n",
    "print(\"\"\"\n",
    "Conclusão\n",
    "\n",
    "A análise de dados realizada ao longo deste projeto fornece uma base sólida para que a CPTM aproveite o poder do Big Data em suas operações diárias. Cada etapa da análise, desde a detecção de outliers até a visualização por meio do PCA, foi desenvolvida com o objetivo de tornar os dados mais acessíveis e úteis para as tomadas de decisão estratégicas da empresa.\n",
    "\n",
    "Identificar outliers nos dados permite à CPTM observar eventos incomuns que podem impactar diretamente a eficiência e segurança de seus serviços. Esses valores extremos, muitas vezes indicativos de incidentes ou variações significativas no fluxo de passageiros, sinalizam pontos que merecem uma atenção especial. A partir desses insights, a CPTM pode direcionar ações preventivas, aprimorar a alocação de recursos e melhorar o atendimento aos usuários.\n",
    "\n",
    "A aplicação de técnicas de redução de dimensionalidade, como o PCA, transforma dados complexos em representações visuais claras e significativas. Isso facilita a comunicação entre as equipes, permitindo que os gestores compreendam rapidamente padrões e tendências importantes, otimizando o planejamento e a operação de seus serviços. Com uma visão mais simplificada, a CPTM está equipada para desenvolver painéis informativos e intuitivos, que podem ser utilizados em diferentes níveis de tomada de decisão.\n",
    "\n",
    "Por fim, essa análise representa um passo importante na construção de um pipeline de Big Data completo, integrado e focado em resultados. Com os dados agora organizados e enriquecidos com insights, a CPTM possui um recurso poderoso para embasar futuras estratégias e responder com agilidade às necessidades do transporte público urbano. Assim, a iniciativa de análise de Big Data da CPTM não apenas eleva o nível de eficiência operacional, mas também contribui para uma experiência de transporte mais segura e confiável para os cidadãos.\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
