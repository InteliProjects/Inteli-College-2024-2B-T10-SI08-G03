{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise tabela de ocorrências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook tem como objetivo realizar uma análise detalhada das ocorrências ferroviárias registradas em um dataset específico. A análise inclui a importação e leitura dos dados, verificação de tipos de dados, análise descritiva e identificação de colunas com valores nulos.\n",
    "\n",
    "## Estrutura do Notebook\n",
    "\n",
    "1. **Importação de Bibliotecas Necessárias**: Importamos as bibliotecas essenciais para manipulação e visualização dos dados.\n",
    "2. **Leitura do Arquivo**: Carregamos o arquivo CSV contendo os dados das ocorrências ferroviárias.\n",
    "3. **Análise Colunar**: Realizamos uma análise rápida para descrever o conteúdo das colunas.\n",
    "4. **Verificação de Tipos de Dados**: Verificamos os tipos de dados presentes em cada coluna.\n",
    "5. **Análise Descritiva**: Calculamos estatísticas descritivas para entender melhor a distribuição dos dados.\n",
    "6. **Identificação de Colunas Nulas**: Identificamos colunas que possuem apenas valores nulos, o que pode ser útil para futuras etapas de limpeza de dados.\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "O objetivo principal é entender a estrutura dos dados, identificar possíveis problemas como colunas vazias e preparar o dataset para análises mais aprofundadas no futuro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo arquivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa etapa, teremos que carregar o arquivo em uma váriavel, com isso verificando se há algum erro no csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(\"..\", \"dados\", \"TABELA_BIG_DATA_FT_OCORRENCIAS.csv\"), encoding=\"utf-16le\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Classificacao Manchete\"] == \"USUÁRIO\"][\"Desc Ocorrencia\"].head()\n",
    "\n",
    "#salvando em um arquivo\n",
    "df[df[\"Classificacao Manchete\"] == \"USUÁRIO\"][\"Desc Ocorrencia\"].to_csv(\"ocorrencias_usuario.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo_relevancia = df[\"Tx Tipo Relevancia\"].value_counts()\n",
    "\n",
    "tipo_relevancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise da tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise colunar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trata-se de uma análise rápida que irá apenas descrever rapidamente o conteudo das colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos primeiramente verificar os tipos dos valores nas colunas, quantidades "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vemos a distribuição, media e outras caracteristicas das colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso, verificamos que algumas colunas possuem apenas valores nulos, o que pode ser comprovado com a seguinte célula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null_cols(df):\n",
    "    n_rows = df.shape[0]\n",
    "    df_nulls = df.isnull().sum()\n",
    "    only_null_cols = df_nulls[df_nulls == n_rows].index\n",
    "    if len(only_null_cols) > 0:\n",
    "        print(f\"Colunas com todos os valores nulos: {list(only_null_cols)}\")\n",
    "    else:\n",
    "        print(\"Não há colunas com todos os valores nulos\")\n",
    "\n",
    "check_null_cols(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código acima compara o numero de linhas no df com o numero de linhas nulas em cada coluna. Se o numero de linhas nulas na coluna for igual ao numero de linhas no df, então temos uma coluna vazia. Nesse caso, encontramos 3 colunas vazias: Data Atualizacao, Eventos Relacionados e Tx Trem, algo que pode ser levado em conta para passos futuros, como uma limpeza de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos verificar a distribuição dos valores em cada uma das colunas que forem relacionadas a alguma classificação, isso deverá ser deduzido a partir do nome da coluna, a fim de entender como os dados estão reunidos e se estão centralizados em algum valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Coluna Categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso, temos os nomes das colunas e, observando a tabela e também o nome da coluna, conseguimos deduzir que Class Manchete e Classificacao Manchete são colunas categóricas, ou seja, não serão dados de uma data, numéricos ou etc, mas sim trarão alguma característica para os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso, a fim de deixar nosso código mais reaproveitavel, a seguinte função gera um grafico de barras sobre a frequência de dados em uma coluna da tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_value_counts_graph(df, col):\n",
    "    value_counts = df[col].value_counts()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(value_counts.index, value_counts.values)\n",
    "    plt.title(f\"Contagem de valores para a coluna {col}\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Contagem de valores para a coluna {col}:\")\n",
    "    print(value_counts)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso, conseguimos realizar a contagem para a coluna Class Manchete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_value_counts_graph(df, \"Class Manchete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora para a coluna Classificacao Manchete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_value_counts_graph(df, \"Classificacao Manchete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apenas visualmente, vemos que a maior parte das ocorrências nas duas classificações são acerca de Usuários e Segurança Pública. Porém podemos provar isso com o Príncipio de pareto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principio de pareto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Princípio de Pareto\n",
    "\n",
    "O Princípio de Pareto, também conhecido como regra 80/20, é um conceito que sugere que, para muitos eventos, aproximadamente 80% dos efeitos vêm de 20% das causas. Esse princípio foi nomeado em homenagem ao economista italiano Vilfredo Pareto, que observou que 80% das terras na Itália eram possuídas por 20% da população.\n",
    "\n",
    "No contexto da análise de dados, o Princípio de Pareto pode ser utilizado para identificar quais fatores ou categorias têm o maior impacto em um determinado resultado. Por exemplo, ao analisar ocorrências ferroviárias, podemos descobrir que 80% dos incidentes são causados por 20% dos fatores identificados. Isso pode ajudar a direcionar esforços e recursos para as áreas que terão o maior impacto na melhoria dos resultados.\n",
    "\n",
    "A aplicação do Princípio de Pareto pode ser visualizada através de gráficos de Pareto, que são gráficos de barras que mostram a frequência ou impacto de diferentes categorias, juntamente com uma linha que representa a contribuição cumulativa dessas categorias para o total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def principio_de_pareto(df, col):\n",
    "    # Calculando a contagem de valores e as porcentagens acumuladas\n",
    "    value_counts = df[col].value_counts()\n",
    "    total = value_counts.sum()\n",
    "    cumsum = value_counts.cumsum()\n",
    "    cumsum_percentage = cumsum / total * 100\n",
    "    \n",
    "    # Definindo o ponto de 80% (incluindo o próximo valor se o anterior não atingir 80%)\n",
    "    pareto_80 = cumsum_percentage[cumsum_percentage <= 80]\n",
    "    if pareto_80.empty or cumsum_percentage.iloc[len(pareto_80)] > 80:\n",
    "        pareto_80 = pd.concat([\n",
    "            cumsum_percentage[cumsum_percentage <= 80],\n",
    "            cumsum_percentage[cumsum_percentage > 80].head(1)\n",
    "        ])\n",
    "    \n",
    "    # Plotando o gráfico com duas y-axes (barras e linha de porcentagem acumulada)\n",
    "    fig, ax1 = plt.subplots(figsize=(18, 6))\n",
    "    \n",
    "    # Barras de frequência\n",
    "    ax1.bar(value_counts.index, value_counts.values, color='blue', alpha=0.7)\n",
    "    ax1.set_xlabel(f\"Valores de {col}\")\n",
    "    ax1.set_ylabel(\"Frequência\", color='blue')\n",
    "    ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "    # Segundo eixo Y para a porcentagem acumulada\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(cumsum_percentage.index, cumsum_percentage.values, color='red', marker='s', linestyle='-', linewidth=2)\n",
    "    ax2.set_ylabel(\"Porcentagem acumulada (%)\", color='red')\n",
    "    ax2.tick_params(axis='y', labelcolor='red')\n",
    "    ax2.axhline(80, color='green', linestyle='--', label='80%')\n",
    "\n",
    "    # Adicionar rótulos para os valores percentuais na linha\n",
    "    for i, v in enumerate(cumsum_percentage.values):\n",
    "        ax2.text(i, v + 2, f'{v:.1f}%', ha='center', va='bottom', fontsize=10, color='red')\n",
    "\n",
    "    # Título e layout\n",
    "    plt.title(f\"Diagrama de Pareto para a coluna {col}\")\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Exibir a legenda\n",
    "    ax2.legend(loc=\"best\")\n",
    "\n",
    "    # Mostrar o gráfico\n",
    "    plt.show()\n",
    "    \n",
    "    # Exibindo os valores até pelo menos 80%\n",
    "    print(f\"Para a coluna {col}, os valores que representam 80% dos dados são:\")\n",
    "    print(pareto_80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `principio_de_pareto` foi definida para aplicar o Princípio de Pareto em uma coluna específica do dataframe. Esta função calcula a contagem de valores, a soma cumulativa e a porcentagem cumulativa dos valores em uma coluna. Em seguida, ela gera um gráfico de barras que mostra a contribuição cumulativa das categorias para o total, permitindo identificar quais categorias têm o maior impacto.\n",
    "\n",
    "Essa função será útil para identificar as categorias mais impactantes nas colunas categóricas do nosso dataset de ocorrências ferroviárias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora iremos aplicar essa função na coluna Classificação Manchete:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principio_de_pareto(df, \"Classificacao Manchete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o gráfico acima, vemos que, 82.2% das ocorrências são causados por ocorrências de segurança pública e usuários, considerando que temos 8 classes e que 2 delas causam mais de 80% das ocorrências, temos um alinhamento com o Princípio de Pareto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porém para ter certeza dos nossos resultados podemos realizar uma dupla validação com a coluna Class Manchete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principio_de_pareto(df, \"Class Manchete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como é possível observar, em ambas as colunas, as classificações de ocorrencias \"SEGURANÇA PÚBLICA\" e \"USUÁRIOS\" são as mais representativas, com isso, ao serem resolvidos problemas relacionados a ambos, seria possível resolver ao menos 80% dos erros encontrados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos tambem elencar os top 10 trechos com mais ocorrências, para isso, podemos obsevar o seguinte código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trechos = df[\"Trecho\"].value_counts().head(10)\n",
    "\n",
    "#gráfico de barras\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(trechos.index, trechos.values)\n",
    "plt.title(\"Top 10 trechos com mais ocorrências\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso, conseguimos ver que a estação do Braz é responsável pela maior parte das ocorrências. Com isso, podemos descobrir quanto das ocorrencias são no Braz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ocorrencias = df.shape[0]\n",
    "braS_ocorrencias = df[\"Trecho\"].value_counts().loc[\"BAS\"]\n",
    "\n",
    "proporcao_bras = braS_ocorrencias / num_ocorrencias * 100\n",
    "\n",
    "print(f\"A proporção de ocorrências no trecho BAS é de {proporcao_bras:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isto é, 10% das ocorrencias são no Bras, o que pode se dar pelo auto movimento na via"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Colunas numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora iremos analisar as colunas numéricas. Com isso, primeiramente devemos identificá-las"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"colunas numéricas\",list(df.select_dtypes(include=['float64', 'int64']).columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando que temos muitas que são \"Id\" ou \"tx\", ou seja, provaveis identificações, vamos análisa-los primeiramente visualmente para entender sobre oque falam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = []\n",
    "for column in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    #se tiver Id no nome da coluna\n",
    "    if \"id\" in column.lower() or \"tx\" in column.lower():\n",
    "        id_cols.append(column)\n",
    "        \n",
    "id_df = df[id_cols]\n",
    "\n",
    "id_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apenas visualmente, conseguimos identificar na tabela, colunas que são referentes a ID's, nelas conseguimos depois  ver por exemplo, em quais localidades há mais ocorrencias, quais trens, tipos de relevancia mais recorrentes, etc. Contudo, por enquanto iremos continuar apenas analisando colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda observando as colunas de ID, vemos data id em duas colunas, o que pode ser convertido para uma data em si."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter_uid_data(uid):\n",
    "    if pd.isnull(uid):\n",
    "        return pd.NaT\n",
    "    data_str = str(int(uid))\n",
    "    return datetime.strptime(data_str, '%Y%m%d')\n",
    "\n",
    "df['Datanormalizacao'] = df['Id Datanormalizacao'].apply(converter_uid_data)\n",
    "df['Dataocorrencia'] = df['Id Dataocorrencia'].apply(converter_uid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análises dos valores nas colunas numéricas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando a tabela, na coluna Id Localidade, conseguimos identificar quais localidades possuiram maior numero de ocorrencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Id Localidade\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso, é possível observar que a localidade 462 possui um maior numero de ocorrencias, agora, combinando isso com a data das ocorrencias(mês e ano), podemos ver em uma linha do tempo o numero de ocorrencias nessa localidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando os dados para a localidade 462\n",
    "df_localidade_462 = df[df[\"Id Localidade\"] == 462]\n",
    "\n",
    "# Criando uma nova coluna 'AnoMes' para agrupar por mês e ano\n",
    "df_localidade_462['AnoMes'] = df_localidade_462['Dataocorrencia'].dt.to_period('M')\n",
    "\n",
    "# Contando o número de ocorrências por mês e ano\n",
    "ocorrencias_por_mes = df_localidade_462.groupby('AnoMes').size()\n",
    "\n",
    "# Plotando o gráfico de linha\n",
    "plt.figure(figsize=(12, 6))\n",
    "ocorrencias_por_mes.plot(kind='line', marker='o')\n",
    "plt.title('Número de Ocorrências na Localidade 462 ao Longo do Tempo')\n",
    "plt.xlabel('Mês e Ano')\n",
    "plt.ylabel('Número de Ocorrências')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A visualização no grafico fica um pouco complicada, mas é possível identificar periodos de pico de ocorrências, porém quero afirmar os periodos com ocorrencias acima da média."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_localidade_462 = df[df[\"Id Localidade\"] == 462]\n",
    "\n",
    "# Criando uma nova coluna 'AnoMes' para agrupar por mês e ano\n",
    "df_localidade_462['AnoMes'] = df_localidade_462['Dataocorrencia'].dt.to_period('M')\n",
    "\n",
    "# Contando o número de ocorrências por mês e ano\n",
    "ocorrencias_por_mes = df_localidade_462.groupby('AnoMes').size()\n",
    "\n",
    "ocorrencias_acima_media = ocorrencias_por_mes[ocorrencias_por_mes > ocorrencias_por_mes.mean()]\n",
    "\n",
    "ocorrencias_acima_media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso, sabemos que 124 periodos tiveram numero de ocorrencias maior que a média de ocorrencias por mês, sendo o periodo com mais ocorrências no mês 7 de 2009."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também podemos identificar as horas com mais numero de ocorrência, para isos precisamos converter a hora para o formato 24 horas e então fazer essa verificação com um mapa de calor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hora Ocorrencia Convertida'] = df['Hora Ocorrencia'].str.replace(\",\",\".\") \n",
    "\n",
    "df['Hora Ocorrencia Convertida'] = pd.to_numeric(df['Hora Ocorrencia Convertida'], errors='coerce') * 24\n",
    "\n",
    "df['Hora Ocorrencia Convertida'] = df['Hora Ocorrencia Convertida'].astype(int)\n",
    "\n",
    "df.head()\n",
    "\n",
    "hora_ocorrencias = df['Hora Ocorrencia Convertida'].value_counts()\n",
    "\n",
    "# heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(hora_ocorrencias.to_frame(), annot=True, fmt='d', cmap='viridis')\n",
    "plt.title('Número de Ocorrências por Hora do Dia')\n",
    "plt.xlabel('Hora do Dia')\n",
    "plt.ylabel('Número de Ocorrências')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estranhamente, o horario com mais registros é as 23 horas, o que não condiz muito com a movimentação para o horario. Talvez isso se de pelo fato de os registros serem feitos apenas ao final do dia e não ao longo dele."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convertendo csv para parquet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar essa tarefa, o grupo desenvolveu uma função de conversão que será importada abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.parquet import Conversor\n",
    "\n",
    "conversor = Conversor()\n",
    "\n",
    "conversor.df_to_parquet(df, \"../dados/ocorrencias.parquet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload de dados para AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar essa tarefa, o grupo desenvolveu uma função de upload que será importada abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.aws_conn import AwsConn\n",
    "\n",
    "aws_conn = AwsConn()\n",
    "\n",
    "aws_conn.send_to_s3(\"ocorrencias.parquet\", \"big-data-ft-ocorrencias\", \"../dados/ocorrencias.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src-ZvBfF1Ly-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
